{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enumerate SRA metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_run_table_filepaths = [\n",
    "    'SRP160434_SraRunTable.txt',\n",
    "    'SRP160435_SraRunTable.txt'\n",
    "]\n",
    "\n",
    "geo_samples_filepaths = [\n",
    "    'GSE119693_Samples.txt'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism_to_genome = {\n",
    "    'Homo sapiens': 'hg38',\n",
    "    'Mus musculus': 'mm10'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df = (\n",
    "    pd.concat([\n",
    "        pd.read_csv(fp)\n",
    "        for fp\n",
    "        in sra_run_table_filepaths\n",
    "    ]).merge(\n",
    "        pd.concat([\n",
    "            pd.read_csv(fp, sep = '\\t')\n",
    "            for fp\n",
    "            in geo_samples_filepaths\n",
    "        ])\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['Genome'] = sra_runs_df['Organism'].map(organism_to_genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df[['GEO_Accession (exp)', 'Sample Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(list(sra_runs_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download SRA runs as fastqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['fastq_dir'] = 'fastqs/' + sra_runs_df['Genome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasterq_dump_threads = 10\n",
    "sra_runs_df['fasterq_dump_cmd'] = (\n",
    "    f'mkdir -p ' + sra_runs_df['fastq_dir'] + ';' +\n",
    "    f'fasterq-dump --outdir ' + sra_runs_df['fastq_dir'] + ' ' +\n",
    "    f'--mem 4G --split-3 --threads {fasterq_dump_threads} ' + \n",
    "    f'--skip-technical  ' + \n",
    "    f'--print-read-nr ' + sra_runs_df['Run']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for cmd in tqdm(list(sra_runs_df['fasterq_dump_cmd'])):\n",
    "    print(cmd)\n",
    "    # ! {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_jobs = 30\n",
    "parallel_cmds_filepath = 'parallel_fasterq_dump_cmds.sh'\n",
    "with open(parallel_cmds_filepath, 'w') as f:\n",
    "    f.write('\\n'.join(list(sra_runs_df['fasterq_dump_cmd']))+'\\n')\n",
    "parallel_cmd = f'cat {parallel_cmds_filepath}|parallel -j {parallel_jobs}'\n",
    "print(parallel_cmd)\n",
    "! {parallel_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cut adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['fastq_filepath'] = sra_runs_df['fastq_dir'] + '/' + sra_runs_df['Run'] + '.fastq'\n",
    "sra_runs_df['trimmed_fastq_filepath'] = sra_runs_df['fastq_dir'] + '/' + sra_runs_df['Run'] + '_trimmed.fq.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_galore_threads = 8\n",
    "sra_runs_df['trim_galore_cmd'] = (\n",
    "    f'trim_galore -j {trim_galore_threads} ' +\n",
    "    f'--fastqc --gzip ' +\n",
    "    f'-o ' + sra_runs_df['fastq_dir'] + ' ' + \n",
    "    sra_runs_df['fastq_filepath'] + \n",
    "    f' &> ' + sra_runs_df['trimmed_fastq_filepath'] + '.log'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmd in tqdm(list(sra_runs_df['trim_galore_cmd'])):\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate genome index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes = sorted(list(set(sra_runs_df['Genome'])))\n",
    "genome_fa_filepaths = [\n",
    "    f'genomes/{genome}/{genome}.fa'\n",
    "    for genome\n",
    "    in genomes\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_to_genome_fa_filepath = {\n",
    "    k: v\n",
    "    for k,v\n",
    "    in zip(\n",
    "        genomes,\n",
    "        genome_fa_filepaths\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowtie2_threads = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowtie2_index_filepaths = [\n",
    "    f'genomes/{genome}/{genome}.bowtie2/index'\n",
    "    for genome\n",
    "    in genomes\n",
    "]\n",
    "\n",
    "bowtie2_index_log_filepaths = [\n",
    "    f'genomes/{genome}/{genome}.bowtie2.log'\n",
    "    for genome\n",
    "    in genomes\n",
    "]\n",
    "\n",
    "\n",
    "bowtie2_build_cmds = [\n",
    "    (\n",
    "        f'mkdir -p $(dirname {bowtie2_index_filepath});'\n",
    "        f'bowtie2-build --threads {bowtie2_threads} {genome_fa_filepath} {bowtie2_index_filepath} '\n",
    "        f'&> {bowtie2_index_log_filepath}'\n",
    "    )\n",
    "    for genome_fa_filepath, bowtie2_index_filepath, bowtie2_index_log_filepath\n",
    "    in zip(\n",
    "        genome_fa_filepaths,\n",
    "        bowtie2_index_filepaths,\n",
    "        bowtie2_index_log_filepaths\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for cmd in tqdm(bowtie2_build_cmds):\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_to_bowtie_index_filepath = {\n",
    "    k: v\n",
    "    for k,v\n",
    "    in zip(\n",
    "        genomes,\n",
    "        bowtie2_index_filepaths\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['sam_filepath'] = (\n",
    "    'alignments/' + sra_runs_df['Genome'] + '/' +\n",
    "    sra_runs_df['Run'] + '.sam'\n",
    ")\n",
    "sra_runs_df['bowtie2_cmd'] = (\n",
    "    f'mkdir -p alignments/' + sra_runs_df['Genome'] + ';'\n",
    "    f'bowtie2 --threads {bowtie2_threads} -x ' +\n",
    "    sra_runs_df['Genome'].map(genome_to_bowtie_index_filepath) + ' ' +\n",
    "    f'-U ' + sra_runs_df['trimmed_fastq_filepath'] + ' ' +\n",
    "    f'-S ' + sra_runs_df['sam_filepath'] +  ' ' +\n",
    "    '&> ' + sra_runs_df['sam_filepath'] + '.log'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmd in tqdm(list(sra_runs_df['bowtie2_cmd'])):\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make tag directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['tagdir_basename'] = (\n",
    "    sra_runs_df['Run'] + '_' + \n",
    "    sra_runs_df['Sample Title']\n",
    ")\n",
    "\n",
    "sra_runs_df['tagdir_filepath'] = (\n",
    "    'tagdirs/' + sra_runs_df['Genome'] + '/' +\n",
    "    sra_runs_df['tagdir_basename'] + '/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_runs_df['tagdir_cmd'] = (\n",
    "    'mkdir -p ' + sra_runs_df['tagdir_filepath'] + ' ; '\n",
    "    'makeTagDirectory ' +\n",
    "    sra_runs_df['tagdir_filepath'] + ' ' +\n",
    "     sra_runs_df['sam_filepath'] + ' ' +\n",
    "    '-single -format sam '\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for cmd in tqdm(list(sra_runs_df['tagdir_cmd'])):\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = sra_runs_df[['Genome','tagdir_basename', 'tagdir_filepath']].copy()\n",
    "samples_df['basename'] = samples_df['tagdir_basename']\n",
    "samples_df['sample'] = True\n",
    "samples_df['group'] = samples_df['basename'].map(lambda x: '_'.join(x.split('_')[1:-1]))\n",
    "samples_df['replicate'] = samples_df['basename'].map(lambda x: int(x.split('_rep')[-1]))\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicate comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_1 = 'ATAC_UT'\n",
    "# group_2 = 'ATAC_LPS-30min'\n",
    "\n",
    "# group_1 = 'H3K27ac_UT'\n",
    "# group_2 = 'H3K27ac_LPS-30min'\n",
    "\n",
    "group_1 = 'ATAC_UT'\n",
    "group_2 = 'ATAC_LPS-1h'\n",
    "\n",
    "# group_1 = 'H3K27ac_UT'\n",
    "# group_2 = 'H3K27ac_LPS-1h'\n",
    "\n",
    "# group_1 = 'ATAC_UT'\n",
    "# group_2 = 'ATAC_LPS-2h'\n",
    "\n",
    "# group_1 = 'H3K27ac_UT'\n",
    "# group_2 = 'H3K27ac_LPS-2h'\n",
    "\n",
    "comparison_prefix = f'walkthrough.mouse_bmdm_lps_stim_atac.{group_1}.vs.{group_2}'\n",
    "\n",
    "# comparison_prefix = f'walkthrough.mouse_bmdm_lps_stim_mnase.{group_1}.vs.{group_2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagdir_filepaths = list(samples_df[(samples_df['sample']) & (samples_df['group'].isin([group_1, group_2]))]['tagdir_filepath'])\n",
    "input_tagdir_filepaths = list(samples_df[(samples_df['sample']==False) & (samples_df['group'].isin([group_1, group_2]))]['tagdir_filepath'])\n",
    "\n",
    "genome = sorted(list(set(samples_df[samples_df['tagdir_filepath'].isin(tagdir_filepaths)]['Genome'])))[0]\n",
    "\n",
    "tagdirs_str = ' '.join(tagdir_filepaths)\n",
    "input_tagdirs_str = ' '.join(input_tagdir_filepaths)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call cleavage sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tss_min = 7\n",
    "\n",
    "tagdirs_opt = f'-d {tagdirs_str}'\n",
    "input_tagdirs_opt = ' ' if (len(input_tagdir_filepaths) == 0) else f'-dinput {input_tagdirs_str}'\n",
    "\n",
    "tss_filepath = f'{comparison_prefix}.tss.min_raw_{tss_min}.txt'\n",
    "\n",
    "get_tss_cmd = (\n",
    "    f'perl getTSSfromReads.noLib.pl '\n",
    "    f'{tagdirs_opt} '\n",
    "    f'{input_tagdirs_opt} '\n",
    "    f'-minRaw {tss_min} '\n",
    "    f'> {tss_filepath}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for cmd in [get_tss_cmd]:\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Quantify cleavage sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_filepath = f'genomes/{genome}/{genome}.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_filepath = tss_filepath[:-len('.txt')]+'.counts.txt'\n",
    "counts_cmd = (\n",
    "    f'annotatePeaks.pl {tss_filepath} '\n",
    "    f'{genome_filepath} '\n",
    "    f'-strand + -fragLength 1 -raw '\n",
    "    f'-d {tagdirs_str} '\n",
    "    f'> {counts_filepath}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlogs_filepath = tss_filepath[:-len('.txt')]+'.rlog.txt'\n",
    "rlogs_cmd = (\n",
    "    f'annotatePeaks.pl {tss_filepath} '\n",
    "    f'{genome_filepath} '\n",
    "    f'-strand + -fragLength 1 -rlog '\n",
    "    f'-d {tagdirs_str} '\n",
    "    f'> {rlogs_filepath}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for cmd in [counts_cmd, rlogs_cmd]:\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head {counts_filepath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_basenames = list(samples_df[samples_df['sample']]['basename'])\n",
    "group_1_basenames = [basename for basename in list(samples_df[samples_df['group'] == group_1]['basename']) if basename in sample_basenames]\n",
    "group_2_basenames = [basename for basename in list(samples_df[samples_df['group'] == group_2]['basename']) if basename in sample_basenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df = pd.read_csv(counts_filepath, sep = '\\t')\n",
    "\n",
    "counts_df_col_renames = {\n",
    "    col: col.split('/')[2]\n",
    "    for col\n",
    "    in (\n",
    "        list(counts_df.columns)\n",
    "        [\n",
    "            -len(\n",
    "                group_1_basenames + group_2_basenames\n",
    "            ):\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "# counts_df_col_renames[list(counts_df.columns)[0]] = 'PeakID'\n",
    "counts_df = counts_df.rename(columns = counts_df_col_renames)\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_counts_filepath = counts_filepath[:-len('.txt')]+f'.comparison.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_counts_df = counts_df.copy()\n",
    "counts_df_col_renames_reverse = {v:k for k,v in counts_df_col_renames.items()}\n",
    "comparison_counts_df_columns = (\n",
    "    (\n",
    "        list(comparison_counts_df.columns)\n",
    "        [:-len(group_1_basenames + group_2_basenames)]\n",
    "    ) + \n",
    "    group_1_basenames + \n",
    "    group_2_basenames\n",
    ")\n",
    "comparison_counts_df = comparison_counts_df[comparison_counts_df_columns].copy()\n",
    "comparison_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_counts_df[group_1_basenames + group_2_basenames].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_counts_df.fillna('NA').to_csv(comparison_counts_filepath, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(comparison_counts_filepath)\n",
    "! head {comparison_counts_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Determine differential cleavage sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_filepath = comparison_counts_filepath[:-len('.txt')]+f'.differential.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename_to_group_codes = samples_df[['basename', 'group']].copy().set_index('basename')['group'].to_dict()\n",
    "basename_to_batch_codes = samples_df[['basename', 'replicate']].copy().set_index('basename')['replicate'].to_dict()\n",
    "\n",
    "group_codes = [basename_to_group_codes[basename] for basename in (group_1_basenames + group_2_basenames)]\n",
    "batch_codes = [basename_to_batch_codes[basename] for basename in (group_1_basenames + group_2_basenames)]\n",
    "\n",
    "group_codes_str = ' '.join(map(str, group_codes))\n",
    "batch_codes_str = ' '.join(map(str, batch_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_expression_cmd = (\n",
    "    f'getDiffExpression.pl {comparison_counts_filepath} '\n",
    "    f'{group_codes_str} '\n",
    "    f'-batch {batch_codes_str} '\n",
    "    f'> {differential_filepath}'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(differential_expression_cmd)\n",
    "! {differential_expression_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head {differential_filepath}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_df = pd.read_csv(differential_filepath, sep = '\\t')\n",
    "differential_df = differential_df.rename(columns = {list(differential_df.columns)[0]:'PeakID'})\n",
    "differential_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_df['Name'] = differential_df['PeakID']\n",
    "differential_df['log2fc'] = differential_df[list(differential_df.columns)[-4]]\n",
    "differential_df['sum'] = differential_df['PeakID'].map(comparison_counts_df.copy().set_index(list(comparison_counts_df.columns)[0])[group_1_basenames + group_2_basenames].sum(axis = 1).to_dict())\n",
    "differential_df = differential_df[differential_df['sum']>=tss_min].copy().reset_index(drop = True)\n",
    "\n",
    "differential_df['Score'] = differential_df['log2fc']\n",
    "\n",
    "differential_df.sort_values('log2fc', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Write differential cleavage sites to BED file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_bed_df = differential_df[['Chr', 'Start', 'End', 'Name', 'Score', 'Strand']].copy()\n",
    "differential_bed_df[['Score']].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differential_bed_filepath = differential_filepath[:-len('.txt')]+'.log2fc.bed'\n",
    "differential_bed_df.to_csv(differential_bed_filepath, sep = '\\t', index = False, header = None)\n",
    "! head {differential_bed_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster differential cleavage sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_slop = 200\n",
    "clustered_bed_filepath = differential_bed_filepath[:-len('.bed')]+f'.cluster_unstranded_slop_{cluster_slop}.bed'\n",
    "cluster_cmd = f'bedtools sort -i {differential_bed_filepath} | bedtools cluster -d {cluster_slop} > {clustered_bed_filepath}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(cluster_cmd)\n",
    "! {cluster_cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_differential_bed_df = pd.read_csv(clustered_bed_filepath, sep = '\\t', header = None, names = ['Chr', 'Start', 'End', 'Name', 'Score', 'Strand', 'Cluster'])\n",
    "clustered_differential_bed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplicate clusters, select site with highest sum\n",
    "was \"highest absolute score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_deduplicated_differential_bed_df = clustered_differential_bed_df.copy()\n",
    "cluster_deduplicated_differential_bed_df['Sum'] = cluster_deduplicated_differential_bed_df['Name'].map(differential_df[['Name', 'sum']].copy().set_index('Name')['sum'].to_dict())\n",
    "cluster_deduplicated_differential_bed_df['Abs_Score'] = cluster_deduplicated_differential_bed_df['Score'].abs()\n",
    "cluster_deduplicated_differential_bed_df['Rank_Score'] = cluster_deduplicated_differential_bed_df['Score'].rank(method = 'dense')\n",
    "\n",
    "dedup_sort_col = 'Sum'\n",
    "dedup_sort_ascending = False\n",
    "\n",
    "cluster_deduplicated_differential_bed_df = (\n",
    "    cluster_deduplicated_differential_bed_df\n",
    "    .sort_values(by = ['Cluster', dedup_sort_col], ascending = [True, dedup_sort_ascending])\n",
    "    .reset_index(drop = True)\n",
    "    .copy()\n",
    "    .drop_duplicates('Cluster')\n",
    "    .reset_index(drop = True)\n",
    "    .copy()\n",
    ")\n",
    "cluster_deduplicated_differential_bed_df[['Score']].hist(bins = 100)\n",
    "plt.show()\n",
    "cluster_deduplicated_differential_bed_df[['Rank_Score']].hist(bins = 100)\n",
    "plt.show()\n",
    "cluster_deduplicated_differential_bed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type = 'asis'\n",
    "score_col = 'Score'\n",
    "# score_type = 'rank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if score_type == 'rank':\n",
    "    score_col = 'Rank_Score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_deduplicated_differential_bed_filepath = clustered_bed_filepath[:-len('.bed')]+f'.cluster_deduplicated.score_type_{score_type}.bed'\n",
    "cluster_deduplicated_differential_bed_df[['Chr', 'Start', 'End', 'Name', score_col, 'Strand']].to_csv(cluster_deduplicated_differential_bed_filepath, sep = '\\t', index = False, header = None)\n",
    "! head {cluster_deduplicated_differential_bed_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run MEPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "slop = 200\n",
    "mepp_filepath = 'mepp_runs/'+cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.slop_{slop}.mepp'\n",
    "motifs_filepath = 'homer.motifs.txt'\n",
    "mepp_cmd = (\n",
    "    f'bedtools slop -s -b {slop} -g {genome_filepath}.fai -i {cluster_deduplicated_differential_bed_filepath} '\n",
    "    f'|python -m mepp.get_scored_fasta -fi {genome_filepath} '\n",
    "    f'-bed - '\n",
    "    f'|python -m mepp.cli '\n",
    "    f'--fa - '\n",
    "    f'--motifs {motifs_filepath} '\n",
    "    f'--out {mepp_filepath} '\n",
    "    f'--perms 200 '\n",
    "    f'--batch 100 '\n",
    "    f'--dgt 50 '\n",
    "    f'--jobs 20 '\n",
    "    f'--gjobs 10 '\n",
    "    f'--nogpu '\n",
    "    f'--dpi 100 '\n",
    "    f'--orientations +,- '\n",
    "    f'&> {mepp_filepath}.log'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(mepp_cmd)\n",
    "! {mepp_cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show MEPP links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mepp_results_table_md = f'[Results table]({mepp_filepath}/results_table_orientation_fwd.html)'\n",
    "mepp_clustermap_md = f'[Clustermap]({mepp_filepath}/clustermap_orientation_fwd.html)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(mepp_results_table_md))\n",
    "display(Markdown(mepp_clustermap_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run Centrimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_set_percent = 25\n",
    "exclusion_percent = 100 - (peak_set_percent * 2)\n",
    "top_percent = (100 - exclusion_percent//2)\n",
    "bottom_percent = 100 - top_percent\n",
    "print(top_percent)\n",
    "print(bottom_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_percentile_threshold = np.percentile(cluster_deduplicated_differential_bed_df['Score'], top_percent)\n",
    "bottom_percentile_threshold = np.percentile(cluster_deduplicated_differential_bed_df['Score'], bottom_percent)\n",
    "print(top_percentile_threshold)\n",
    "print(bottom_percentile_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cluster_deduplicated_differential_bed_df = cluster_deduplicated_differential_bed_df[cluster_deduplicated_differential_bed_df['Score']>=top_percentile_threshold]\n",
    "bottom_cluster_deduplicated_differential_bed_df = cluster_deduplicated_differential_bed_df[cluster_deduplicated_differential_bed_df['Score']<=bottom_percentile_threshold]\n",
    "print(top_cluster_deduplicated_differential_bed_df.shape)\n",
    "print(bottom_cluster_deduplicated_differential_bed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cluster_deduplicated_differential_bed_filepath = cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.top_{top_percent}_pct.bed'\n",
    "bottom_cluster_deduplicated_differential_bed_filepath = cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.bottom_{bottom_percent}_pct.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cluster_deduplicated_differential_bed_df.to_csv(top_cluster_deduplicated_differential_bed_filepath, sep = '\\t', index = False, header = None)\n",
    "bottom_cluster_deduplicated_differential_bed_df.to_csv(bottom_cluster_deduplicated_differential_bed_filepath, sep = '\\t', index = False, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cluster_deduplicated_differential_fa_filepath = top_cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.slop_{slop}.fa'\n",
    "bottom_cluster_deduplicated_differential_fa_filepath = bottom_cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.slop_{slop}.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fa_cmd = (\n",
    "    f'bedtools slop -s -b {slop} -g {genome_filepath}.fai -i {top_cluster_deduplicated_differential_bed_filepath} '\n",
    "    f'|python -m mepp.get_scored_fasta -fi {genome_filepath} '\n",
    "    f'-bed - '\n",
    "    f'> {top_cluster_deduplicated_differential_fa_filepath}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_fa_cmd = (\n",
    "    f'bedtools slop -s -b {slop} -g {genome_filepath}.fai -i {bottom_cluster_deduplicated_differential_bed_filepath} '\n",
    "    f'|python -m mepp.get_scored_fasta -fi {genome_filepath} '\n",
    "    f'-bed - '\n",
    "    f'> {bottom_cluster_deduplicated_differential_fa_filepath}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmd in [top_fa_cmd, bottom_fa_cmd]:\n",
    "    print(cmd)\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_motifs_filepath = 'homer.motifs.id_fixed.meme'\n",
    "centrimo_filepath = 'centrimo_runs/'+cluster_deduplicated_differential_bed_filepath[:-len('.bed')]+f'.top_vs_bottom_{peak_set_percent}_pct.slop_{slop}.centrimo'\n",
    "centrimo_cmd = (\n",
    "    f'mkdir -p {centrimo_filepath} ;'\n",
    "    f'$(which time) --verbose '\n",
    "    f'centrimo --oc {centrimo_filepath} '\n",
    "    f'--neg {bottom_cluster_deduplicated_differential_fa_filepath} '\n",
    "    f'--norc --sep --local --noseq '\n",
    "    f'{top_cluster_deduplicated_differential_fa_filepath} '\n",
    "    f'{meme_motifs_filepath}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(centrimo_cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
